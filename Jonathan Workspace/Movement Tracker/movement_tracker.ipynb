{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFIG FLAGS ===\n",
    "ANNOTATE_VIDEO = True  # Set to False if you don't want to save or draw video\n",
    "video_path = \"presentation.mp4\"\n",
    "output_video_path = \"annotated_output.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MediaPipe Pose for pose detection\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5)\n",
    "mp_drawing = mp.solutions.drawing_utils  # (Optional) used for drawing pose landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 1: Load the presentation video ===\n",
    "cap = cv2.VideoCapture(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get video metadata\n",
    "fps = cap.get(cv2.CAP_PROP_FPS) # Frames per second\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) # Width of the video frames\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) # Height of the video frames\n",
    "frame_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only create video writer if annotation is enabled\n",
    "if ANNOTATE_VIDEO:\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Tracking Data ===\n",
    "positions = []        # Normalized horizontal positions per frame\n",
    "trail_pixels = []     # Pixel positions for visual trail\n",
    "movement_by_second = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Process Video Frame-by-Frame ===\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = pose.process(frame_rgb)\n",
    "\n",
    "    frame_sec = int(frame_count / fps)\n",
    "\n",
    "    if results.pose_landmarks:\n",
    "        # Draw landmarks and center if annotation is enabled\n",
    "        if ANNOTATE_VIDEO:\n",
    "            mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "        # Get shoulder landmarks\n",
    "        left = results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER]\n",
    "        right = results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER]\n",
    "\n",
    "        # Calculate normalized and pixel center\n",
    "        norm_x = (left.x + right.x) / 2\n",
    "        positions.append((frame_sec, norm_x))\n",
    "\n",
    "        center_x = int(norm_x * width)\n",
    "        center_y = int((left.y + right.y) / 2 * height)\n",
    "        trail_pixels.append((center_x, center_y))\n",
    "\n",
    "        if ANNOTATE_VIDEO:\n",
    "            cv2.circle(frame, (center_x, center_y), 6, (0, 0, 255), -1)\n",
    "    else:\n",
    "        positions.append((frame_sec, None))\n",
    "\n",
    "    # Draw movement trail (blue lines)\n",
    "    if ANNOTATE_VIDEO:\n",
    "        for i in range(1, len(trail_pixels)):\n",
    "            cv2.line(frame, trail_pixels[i - 1], trail_pixels[i], (255, 0, 0), 2)\n",
    "        out.write(frame)\n",
    "    \n",
    "    # Count frame\n",
    "    frame_count += 1\n",
    "\n",
    "cap.release()\n",
    "if ANNOTATE_VIDEO:\n",
    "    out.release()\n",
    "    print(\"âœ… Annotated video saved:\", output_video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 3: Aggregate positions per second ===\n",
    "\n",
    "# Calculate total number of seconds in the video\n",
    "seconds = int(frame_count / fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for sec in range(seconds):\n",
    "    sec_positions = [p for t, p in positions if t == sec and p is not None]\n",
    "\n",
    "    if sec_positions:\n",
    "        # Calculate average X position for the second\n",
    "        avg_position = sum(sec_positions) / len(sec_positions)\n",
    "        movement_by_second.append((sec, avg_position))\n",
    "    else:\n",
    "        # No position detected in this second\n",
    "        movement_by_second.append((sec, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 4: Output movement data ===\n",
    "\n",
    "# Print the second-by-second normalized horizontal position\n",
    "print(\"\\n=== Presenter Movement Summary ===\")\n",
    "for timestamp, pos in movement_by_second:\n",
    "    if pos is not None:\n",
    "        print(f\"Second {timestamp}: Normalized X Position = {pos:.3f}\")\n",
    "    else:\n",
    "        print(f\"Second {timestamp}: No presenter detected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show Lineplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract timestamps and positions (excluding None)\n",
    "timestamps = [t for t, p in movement_by_second if p is not None]\n",
    "positions = [p for t, p in movement_by_second if p is not None]\n",
    "\n",
    "# Create the line plot\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(timestamps, positions, marker='o', linestyle='-', linewidth=2)\n",
    "\n",
    "plt.title(\"Presenter's Movement Over Time\")\n",
    "plt.xlabel(\"Time (seconds)\")\n",
    "plt.ylabel(\"Normalized Horizontal Position (0 = left, 1 = right)\")\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the resolution of the heatmap (e.g., 10 bins across the screen width)\n",
    "num_bins = 20\n",
    "heatmap = np.zeros(num_bins)\n",
    "\n",
    "# Fill the heatmap based on position per second\n",
    "for sec, pos in movement_by_second:\n",
    "    if pos is not None:\n",
    "        bin_index = int(pos * (num_bins - 1))\n",
    "        heatmap[bin_index] += 1  # Count how often the presenter was in this zone\n",
    "\n",
    "# Normalize for display\n",
    "heatmap_normalized = heatmap / np.max(heatmap)\n",
    "\n",
    "# === Plotting the 1D heatmap ===\n",
    "plt.figure(figsize=(10, 2))\n",
    "plt.bar(range(num_bins), heatmap_normalized, width=1.0, color='red')\n",
    "plt.title(\"Presenter Movement Heatmap (Left to Right)\")\n",
    "plt.xlabel(\"Horizontal Frame Zones (0 = Left, 19 = Right)\")\n",
    "plt.ylabel(\"Normalized Presence Frequency\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
